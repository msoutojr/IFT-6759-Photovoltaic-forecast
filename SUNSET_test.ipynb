{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data.ImageData as ImageData\n",
    "import models.SUNSET as SUNSET\n",
    "import functions.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define folder location\n",
    "\n",
    "dir_path = os.getcwd()\n",
    "data_folder = os.path.join(dir_path, \"data\")\n",
    "\n",
    "#define file location\n",
    "\n",
    "images_trainval_path = os.path.join(data_folder,'images_trainval.npy')\n",
    "pv_log_trainval_path = os.path.join(data_folder,'pv_log_trainval.npy')\n",
    "datetime_trainval_path = os.path.join(data_folder,'datetime_trainval.npy')\n",
    "\n",
    "images_test_path = os.path.join(data_folder,'images_test.npy')\n",
    "pv_log_test_path = os.path.join(data_folder,'pv_log_test.npy')\n",
    "datetime_test_path = os.path.join(data_folder,'datetime_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load PV output and images for the trainval set\n",
    "\n",
    "pv_log_trainval = np.load(pv_log_trainval_path)\n",
    "images_trainval = np.load(images_trainval_path)\n",
    "images_trainval = images_trainval.reshape(images_trainval.shape[0],3,64,64)\n",
    "datetimes_trainval = np.load(datetime_trainval_path, allow_pickle=True)\n",
    "\n",
    "# load PV output and images for the test set\n",
    "\n",
    "pv_log_test = np.load(pv_log_test_path)\n",
    "images_test = np.load(images_test_path)\n",
    "images_test = images_test.reshape(images_test.shape[0],3,64,64)\n",
    "datetimes_test = np.load(datetime_test_path, allow_pickle=True)\n",
    "\n",
    "\n",
    "#  ATENTION !!!! Create a dev dataset version ***************************************************************\n",
    "pv_log_trainval = pv_log_trainval[0:2000]\n",
    "images_trainval = images_trainval[0:2000]\n",
    "datetimes_trainval = datetimes_trainval[0:2000]\n",
    "\n",
    "pv_log_test = pv_log_test[0:400]\n",
    "images_test = images_test[0:400]\n",
    "datetimes_test = datetimes_test[0:400]\n",
    "#  ATENTION !!!! ********************************************************************************************\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Dataset classes\n",
    "\n",
    "train_data = ImageData.ImageData(torch.tensor(images_trainval), torch.tensor(pv_log_trainval))\n",
    "test_data = ImageData.ImageData(torch.tensor(images_test),torch.tensor(pv_log_test))\n",
    "\n",
    "# Dataloaders\n",
    "\n",
    "batch_size = 256\n",
    "batch_size_eval = 256\n",
    "\n",
    "indices = list(range(train_data.__len__()))\n",
    "n_valid = train_data.__len__() // 5 # 20% train data\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=batch_size,\n",
    "    sampler=SubsetRandomSampler(indices[:-n_valid]), # we need to split data before that\n",
    "    #num_workers=1,\n",
    "    #pin_memory=use_cuda\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=batch_size_eval,\n",
    "    sampler=SubsetRandomSampler(indices[-n_valid:]), # we need to split data before that\n",
    "    #num_workers=1,\n",
    "    #pin_memory=use_cuda,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=batch_size_eval,\n",
    "    #num_workers=1,\n",
    "    #pin_memory=use_cuda,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marcos\\Documents\\UdeM\\IFT-6759-Photovoltaic-forecast\\data\\ImageData.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(self.inputs[index])\n",
      "C:\\Users\\Marcos\\Documents\\UdeM\\IFT-6759-Photovoltaic-forecast\\data\\ImageData.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.labels[index])\n",
      "C:\\Users\\Marcos\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:520: UserWarning: Using a target size (torch.Size([256])) that is different to the input size (torch.Size([256, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Marcos\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:520: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "### We initialize the parameters\n",
    "\n",
    "num_epochs = 5\n",
    "learning_rate = 3e-6\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "#model = SUNSET.SUNSETBase()\n",
    "model = SUNSET.SUNSET_Sunny()\n",
    "#model = SUNSET.SUNSET_Cloudy()\n",
    "#model = SUNSET.SUNSET_Overcast()\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters() , lr=learning_rate)\n",
    "\n",
    "Losses = []\n",
    "Tlosses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    Losses.append(utils.train(model, train_loader, optimizer, loss_fn).item())    \n",
    "    Tlosses.append(utils.test(model, train_loader, loss_fn).item())\n",
    "    print(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tlosses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Losses = list(map(int, Losses))\n",
    "#Tlosses = list(map(int, Tlosses))\n",
    "#plt.plot(range(num_epochs), Losses)\n",
    "#plt.plot(range(num_epochs), Tlosses)\n",
    "#plt.xlabel('epochs')\n",
    "#plt.ylabel('mean squared loss')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
